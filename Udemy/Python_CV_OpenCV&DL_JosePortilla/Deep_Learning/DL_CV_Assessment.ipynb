{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 5us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 15s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f260a5aef60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = x_train[100]\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/x_train.max()\n",
    "x_test = x_test/x_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train,10)\n",
    "y_cat_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dropout,Activation,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.4043 - acc: 0.8569\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.2786 - acc: 0.9009\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.2385 - acc: 0.9142\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2144 - acc: 0.9238\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1961 - acc: 0.9299\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1828 - acc: 0.9357\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1685 - acc: 0.9415\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1578 - acc: 0.9448\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1480 - acc: 0.9472\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1405 - acc: 0.9503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26144182e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_cat_train,verbose=1,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 61us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2985436358526349, 0.9129]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.87      0.85      0.86      1000\n",
      "          3       0.92      0.93      0.93      1000\n",
      "          4       0.85      0.87      0.86      1000\n",
      "          5       0.98      0.98      0.98      1000\n",
      "          6       0.76      0.75      0.75      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.98      0.98      1000\n",
      "          9       0.97      0.96      0.97      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "prediction = model.predict_classes(x_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
